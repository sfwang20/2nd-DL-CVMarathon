{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Xception backbone做 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b47b0cb432a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.datasets import cifar10\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "\n",
    "#include_top 決定要不要加入 fully Connected Layer\n",
    "\n",
    "'''Xception 架構'''\n",
    "# model=keras.applications.xception.Xception(include_top=False, weights='imagenet',\n",
    "#                                            input_tensor=input_tensor,pooling=None, classes=2)\n",
    "'''Resnet 50 架構'''\n",
    "model=keras.applications.ResNet50(input_shape=(32,32,3), include_top=False, \n",
    "                                  weights='imagenet', pooling=None, classes=10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加層數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model深度： 179\n"
     ]
    }
   ],
   "source": [
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(activation='relu', units=128,)(x)\n",
    "x = Dropout(rate=0.1)(x)\n",
    "predictions = Dense(activation='softmax', units=10)(x)\n",
    "model = Model(inputs=model.input, outputs=predictions)\n",
    "print('Model深度：', len(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "鎖定特定幾層不要更新權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[100:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "準備 Cifar 10 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train, X_test):\n",
    "        mean = np.mean(X_train, axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0,1,2,3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test = normalize(x_train, x_test) \n",
    "\n",
    "## OneHot Label 由(None, 1)-(None, 10)b\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot = OneHotEncoder()\n",
    "y_train = one_hot.fit_transform(y_train).toarray() # y_train的shape為(50000, 1)\n",
    "y_test = one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from tensorflow.compat.v1 import keras\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement=True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction=0.5\n",
    "\n",
    "keras.backend.set_session(InteractiveSession(config=config))\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.7414 - accuracy: 0.3818\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.4587 - accuracy: 0.4853\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3666 - accuracy: 0.5196\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.3176 - accuracy: 0.5408\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.2708 - accuracy: 0.5544\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.2372 - accuracy: 0.5657\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.1986 - accuracy: 0.5758\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.1328 - accuracy: 0.5990\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.0967 - accuracy: 0.6132\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.0550 - accuracy: 0.6304\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.0411 - accuracy: 0.6303\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.9927 - accuracy: 0.6459\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.9826 - accuracy: 0.6501\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.9314 - accuracy: 0.6684\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.9092 - accuracy: 0.6795\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.8869 - accuracy: 0.6844\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.8696 - accuracy: 0.6867\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.8173 - accuracy: 0.7078\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.7793 - accuracy: 0.7229\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.7836 - accuracy: 0.7199\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.7483 - accuracy: 0.7294\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.7344 - accuracy: 0.7343\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.7185 - accuracy: 0.7412\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6798 - accuracy: 0.7566\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6741 - accuracy: 0.7593\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6809 - accuracy: 0.7565\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6413 - accuracy: 0.7720\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6146 - accuracy: 0.7781\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.6231 - accuracy: 0.7745\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5996 - accuracy: 0.7874\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5754 - accuracy: 0.7930\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5446 - accuracy: 0.8028\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5411 - accuracy: 0.8032\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5428 - accuracy: 0.8045\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5241 - accuracy: 0.8098\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5225 - accuracy: 0.8127\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5098 - accuracy: 0.8168\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5512 - accuracy: 0.8008\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5199 - accuracy: 0.8131\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.4949 - accuracy: 0.8235\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.4626 - accuracy: 0.8342\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.4475 - accuracy: 0.8405\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.4704 - accuracy: 0.8319\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.4557 - accuracy: 0.8386\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.4512 - accuracy: 0.8391\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.4116 - accuracy: 0.8530\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.4071 - accuracy: 0.8547\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.4134 - accuracy: 0.8527\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.3926 - accuracy: 0.8605\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.4014 - accuracy: 0.8579\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3942 - accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3765 - accuracy: 0.8650\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3794 - accuracy: 0.8626\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3782 - accuracy: 0.8629\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3634 - accuracy: 0.8672\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3558 - accuracy: 0.8760\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3404 - accuracy: 0.8821\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3421 - accuracy: 0.8809\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.3316 - accuracy: 0.8836\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3644 - accuracy: 0.8729\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3610 - accuracy: 0.8715\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3265 - accuracy: 0.8828\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3254 - accuracy: 0.8852\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3211 - accuracy: 0.8830\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3059 - accuracy: 0.8909\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3041 - accuracy: 0.8948\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3194 - accuracy: 0.8867\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3035 - accuracy: 0.8941\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2736 - accuracy: 0.9053\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2789 - accuracy: 0.9041\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2801 - accuracy: 0.9031\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2765 - accuracy: 0.9042\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2977 - accuracy: 0.8924\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2766 - accuracy: 0.8995\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2604 - accuracy: 0.9088\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2707 - accuracy: 0.9079\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.2528 - accuracy: 0.9140\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.3074 - accuracy: 0.8964\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2552 - accuracy: 0.9112\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2517 - accuracy: 0.9117\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.2528 - accuracy: 0.9113\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2456 - accuracy: 0.9170\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2436 - accuracy: 0.9171\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2365 - accuracy: 0.9186\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2335 - accuracy: 0.9199\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2417 - accuracy: 0.9184\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2733 - accuracy: 0.9099\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2620 - accuracy: 0.9136\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2655 - accuracy: 0.9088\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2314 - accuracy: 0.9217\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2290 - accuracy: 0.9210\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2316 - accuracy: 0.9214\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2208 - accuracy: 0.9236\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2127 - accuracy: 0.9276\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2348 - accuracy: 0.9207\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2165 - accuracy: 0.9254\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2262 - accuracy: 0.9217\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2237 - accuracy: 0.9213\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2121 - accuracy: 0.9245\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.2097 - accuracy: 0.9266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7effb816ef10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "yolo_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
